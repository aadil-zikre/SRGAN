{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T22:03:01.474637Z",
     "start_time": "2024-04-20T22:03:01.183082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-20 18:03:01,473 :: [INFO] :: Logger initialized WITHOUT file handler\n"
     ]
    }
   ],
   "source": [
    "from az_common_funcs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T22:03:02.442955Z",
     "start_time": "2024-04-20T22:03:01.475834Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-06T16:05:29.356080Z",
     "iopub.status.busy": "2024-04-06T16:05:29.355664Z",
     "iopub.status.idle": "2024-04-06T16:05:35.484860Z",
     "shell.execute_reply": "2024-04-06T16:05:35.484076Z",
     "shell.execute_reply.started": "2024-04-06T16:05:29.356054Z"
    },
    "executionInfo": {
     "elapsed": 7330,
     "status": "ok",
     "timestamp": 1712538066791,
     "user": {
      "displayName": "Aadil Iliyas Zikre",
      "userId": "11139065713760395341"
     },
     "user_tz": 240
    },
    "id": "rhFeREYjteTk"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azikre/aadil/venvs/season4/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/azikre/aadil/venvs/season4/lib/python3.11/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "## generator_loss.py\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.vgg import vgg19\n",
    "\n",
    "class TVLoss(nn.Module):\n",
    "    def __init__(self, tv_loss_weight=1):\n",
    "        super(TVLoss, self).__init__()\n",
    "        self.tv_loss_weight = tv_loss_weight\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, c_x, h_x, w_x = x.size()\n",
    "        count_h = self.tensor_size(x[:, :, 1:, :])\n",
    "        count_w = self.tensor_size(x[:, :, :, 1:])\n",
    "        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()\n",
    "        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()\n",
    "        return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
    "\n",
    "    @staticmethod\n",
    "    def tensor_size(t):\n",
    "        return t.size()[1] * t.size()[2] * t.size()[3]\n",
    "\n",
    "class GeneratorLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorLoss, self).__init__()\n",
    "        vgg = vgg19(pretrained=True)\n",
    "        loss_network = nn.Sequential(*list(vgg.features)[:37]).eval()\n",
    "        for param in loss_network.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.loss_network = loss_network\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        self.tv_loss = TVLoss()\n",
    "\n",
    "    def forward(self, out_labels, out_images, target_images):\n",
    "        # Adversarial Loss\n",
    "        adversarial_loss = torch.mean(1 - out_labels)\n",
    "        # Perception Loss\n",
    "        perception_loss = self.l1_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
    "        # Image Loss\n",
    "        image_loss = self.mse_loss(out_images, target_images)\n",
    "        # TV Loss\n",
    "        tv_loss = self.tv_loss(out_images)\n",
    "        return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T22:03:02.451537Z",
     "start_time": "2024-04-20T22:03:02.444311Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-06T16:05:35.486863Z",
     "iopub.status.busy": "2024-04-06T16:05:35.486428Z",
     "iopub.status.idle": "2024-04-06T16:05:35.503375Z",
     "shell.execute_reply": "2024-04-06T16:05:35.502379Z",
     "shell.execute_reply.started": "2024-04-06T16:05:35.486838Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1712538066792,
     "user": {
      "displayName": "Aadil Iliyas Zikre",
      "userId": "11139065713760395341"
     },
     "user_tz": 240
    },
    "id": "YgSy3z-mteTl"
   },
   "outputs": [],
   "source": [
    "## generator.py\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ganGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ganGenerator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, stride=1, padding=4)\n",
    "        self.prelu1 = nn.PReLU()\n",
    "        # 16 blocks\n",
    "        self.GRB1 = GeneratorResidualBlock()\n",
    "        self.GRB2 = GeneratorResidualBlock()\n",
    "        self.GRB3 = GeneratorResidualBlock()\n",
    "        self.GRB4 = GeneratorResidualBlock()\n",
    "        self.GRB5 = GeneratorResidualBlock()\n",
    "        self.GRB6 = GeneratorResidualBlock()\n",
    "        self.GRB7 = GeneratorResidualBlock()\n",
    "        self.GRB8 = GeneratorResidualBlock()\n",
    "        self.GRB9 = GeneratorResidualBlock()\n",
    "        self.GRB10 = GeneratorResidualBlock()\n",
    "        self.GRB11 = GeneratorResidualBlock()\n",
    "        self.GRB12 = GeneratorResidualBlock()\n",
    "        self.GRB13 = GeneratorResidualBlock()\n",
    "        self.GRB14 = GeneratorResidualBlock()\n",
    "        self.GRB15 = GeneratorResidualBlock()\n",
    "        self.GRB16 = GeneratorResidualBlock()\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pxlshuffle1 = nn.PixelShuffle(2)\n",
    "        self.prelu2 = nn.PReLU()\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.pxlshuffle2 = nn.PixelShuffle(2)\n",
    "        self.prelu3 = nn.PReLU()\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=9, stride=1, padding=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.prelu1(x1)\n",
    "\n",
    "        x2 = self.GRB1(x1)\n",
    "        x2 = self.GRB2(x2)\n",
    "        x2 = self.GRB3(x2)\n",
    "        x2 = self.GRB4(x2)\n",
    "        x2 = self.GRB5(x2)\n",
    "        x2 = self.GRB6(x2)\n",
    "        x2 = self.GRB7(x2)\n",
    "        x2 = self.GRB8(x2)\n",
    "        x2 = self.GRB9(x2)\n",
    "        x2 = self.GRB10(x2)\n",
    "        x2 = self.GRB11(x2)\n",
    "        x2 = self.GRB12(x2)\n",
    "        x2 = self.GRB13(x2)\n",
    "        x2 = self.GRB14(x2)\n",
    "        x2 = self.GRB15(x2)\n",
    "        x2 = self.GRB16(x2)\n",
    "\n",
    "        x2 = self.conv2(x2)\n",
    "        x2 = self.bn1(x2)\n",
    "        x3 = x1 + x2\n",
    "\n",
    "        x3 = self.conv3(x3)\n",
    "        x3 = self.pxlshuffle1(x3)\n",
    "        x3 = self.prelu2(x3)\n",
    "        x3 = self.conv4(x3)\n",
    "        x3 = self.pxlshuffle2(x3)\n",
    "        x4 = self.prelu3(x3)\n",
    "\n",
    "        x5 = self.conv5(x4)\n",
    "\n",
    "        return x5\n",
    "\n",
    "class GeneratorResidualBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorResidualBlock, self).__init__()\n",
    "        # convolution\n",
    "        self.conv1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        # batchnorm\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        # prelu\n",
    "        self.prelu1 = nn.PReLU()\n",
    "        #convolution\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        # batchnorm\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        # prelu\n",
    "        self.prelu2 = nn.PReLU()\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.prelu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.prelu2(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T22:03:02.460500Z",
     "start_time": "2024-04-20T22:03:02.453107Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-06T16:05:35.505012Z",
     "iopub.status.busy": "2024-04-06T16:05:35.504720Z",
     "iopub.status.idle": "2024-04-06T16:05:35.523659Z",
     "shell.execute_reply": "2024-04-06T16:05:35.522758Z",
     "shell.execute_reply.started": "2024-04-06T16:05:35.504987Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1712538066792,
     "user": {
      "displayName": "Aadil Iliyas Zikre",
      "userId": "11139065713760395341"
     },
     "user_tz": 240
    },
    "id": "bhhR5to1teTl"
   },
   "outputs": [],
   "source": [
    "## discriminator.py\n",
    "import torch.nn as nn\n",
    "\n",
    "class ganDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ganDiscriminator, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1)\n",
    "        self.lrelu1 = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.lrelu2 = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.lrelu3 = nn.LeakyReLU(0.2)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.lrelu4 = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1)\n",
    "        self.bn5 = nn.BatchNorm2d(256)\n",
    "        self.lrelu5 = nn.LeakyReLU(0.2)\n",
    "        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=2)\n",
    "        self.bn6 = nn.BatchNorm2d(256)\n",
    "        self.lrelu6 = nn.LeakyReLU(0.2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1)\n",
    "        self.bn7 = nn.BatchNorm2d(512)\n",
    "        self.lrelu7 = nn.LeakyReLU(0.2)\n",
    "        self.conv8 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=2)\n",
    "        self.bn8 = nn.BatchNorm2d(512)\n",
    "        self.lrelu8 = nn.LeakyReLU(0.2)\n",
    "\n",
    "        # self.flat = nn.Flatten()\n",
    "\n",
    "        # self.dense9 = nn.Linear(in_features=60*124*512, out_features=1024, bias=True)\n",
    "        # self.lrelu9 = nn.LeakyReLU()\n",
    "\n",
    "        # self.dense10 = nn.Linear(in_features=1024, out_features=1, bias=True)\n",
    "        # self.sigmoid10 = nn.Sigmoid()\n",
    "\n",
    "        self.adaptive_pool_1 = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv9 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=1)\n",
    "        self.lrelu9 = nn.LeakyReLU(0.2)\n",
    "        self.conv10 = nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=1)\n",
    "        self.sigmoid9 = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.lrelu1(x1)\n",
    "\n",
    "        x2 = self.conv2(x1)\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = self.lrelu2(x2)\n",
    "\n",
    "        x3 = self.conv3(x2)\n",
    "        x3 = self.bn3(x3)\n",
    "        x3 = self.lrelu3(x3)\n",
    "\n",
    "        x4 = self.conv4(x3)\n",
    "        x4 = self.bn4(x4)\n",
    "        x4 = self.lrelu4(x4)\n",
    "\n",
    "        x5 = self.conv5(x4)\n",
    "        x5 = self.bn5(x5)\n",
    "        x5 = self.lrelu5(x5)\n",
    "\n",
    "        x6 = self.conv6(x5)\n",
    "        x6 = self.bn6(x6)\n",
    "        x6 = self.lrelu6(x6)\n",
    "\n",
    "        x7 = self.conv7(x6)\n",
    "        x7 = self.bn7(x7)\n",
    "        x7 = self.lrelu7(x7)\n",
    "\n",
    "        x8 = self.conv8(x7)\n",
    "        x8 = self.bn8(x8)\n",
    "        x8 = self.lrelu8(x8)\n",
    "\n",
    "        x9 = self.adaptive_pool_1(x8)\n",
    "        x9 = self.conv9(x9)\n",
    "        x9 = self.lrelu9(x9)\n",
    "\n",
    "        x10 = self.conv10(x9)\n",
    "        x10 = self.sigmoid9(x10.view(x10.size()[0]))\n",
    "\n",
    "        # x9 = self.flat(x8)\n",
    "        # x10 = self.dense9(x9)\n",
    "        # x10 = self.lrelu9(x10)\n",
    "        # x11 = self.dense10(x10)\n",
    "        # x11 = self.sigmoid10(x11)\n",
    "\n",
    "        x11 = x10\n",
    "\n",
    "        return x11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T22:03:02.468183Z",
     "start_time": "2024-04-20T22:03:02.461616Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-06T16:05:35.525710Z",
     "iopub.status.busy": "2024-04-06T16:05:35.525411Z",
     "iopub.status.idle": "2024-04-06T16:05:35.542774Z",
     "shell.execute_reply": "2024-04-06T16:05:35.541851Z",
     "shell.execute_reply.started": "2024-04-06T16:05:35.525678Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1712538066792,
     "user": {
      "displayName": "Aadil Iliyas Zikre",
      "userId": "11139065713760395341"
     },
     "user_tz": 240
    },
    "id": "GKb__UEQteTl"
   },
   "outputs": [],
   "source": [
    "## data_utils.py\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, ToTensor, ToPILImage, CenterCrop, transforms, Resize\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
    "\n",
    "hr_target_size = (96, 96)\n",
    "\n",
    "hr_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.rotate(0) if img.size[0] > img.size[1] else img.rotate(90)),\n",
    "    transforms.CenterCrop(hr_target_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "lr_target_size = (96 // 4, 96 // 4)\n",
    "\n",
    "lr_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.rotate(0) if img.size[0] > img.size[1] else img.rotate(90)),\n",
    "    transforms.CenterCrop(hr_target_size),\n",
    "    transforms.Resize(lr_target_size, interpolation=Image.BICUBIC),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "class Div2kTrainDataset(Dataset):\n",
    "    def __init__(self, hr_base_dir):\n",
    "        super(Div2kTrainDataset, self).__init__()\n",
    "\n",
    "        self.hr_base_dir = hr_base_dir\n",
    "\n",
    "        self.hr_image_filenames = [f'{self.hr_base_dir}/{i}.png' for i in range(0, 4900)]\n",
    "\n",
    "        self.hr_transform = hr_transform\n",
    "        self.lr_transform = lr_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hr_image = self.hr_transform(Image.open(self.hr_image_filenames[index]))\n",
    "        lr_image = self.lr_transform(Image.open(self.hr_image_filenames[index]))\n",
    "        return hr_image, lr_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hr_image_filenames)\n",
    "\n",
    "class Div2kValDataset(Dataset):\n",
    "    def __init__(self, hr_base_dir):\n",
    "        super(Div2kValDataset, self).__init__()\n",
    "\n",
    "        self.hr_base_dir = hr_base_dir\n",
    "\n",
    "        self.hr_image_filenames = [f'{self.hr_base_dir}/{i}.png' for i in range(4900, 5000)]\n",
    "\n",
    "        self.hr_transform = hr_transform\n",
    "        self.lr_transform = lr_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        hr_image = self.hr_transform(Image.open(self.hr_image_filenames[index]))\n",
    "        lr_image = self.lr_transform(Image.open(self.hr_image_filenames[index]))\n",
    "        return hr_image, lr_image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hr_image_filenames)\n",
    "\n",
    "def display_transform():\n",
    "    return Compose([\n",
    "        ToPILImage(),\n",
    "        Resize(96),\n",
    "        CenterCrop(96),\n",
    "        ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T22:03:02.720866Z",
     "start_time": "2024-04-20T22:03:02.469266Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def compute_metrics_batch(hr_batch, sr_batch):\n",
    "    n = hr_batch.shape[0]  # Number of elements in the batch\n",
    "    psnr_values = np.zeros(n)\n",
    "    ssim_values = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        hr = hr_batch[i]\n",
    "        sr = sr_batch[i]\n",
    "        \n",
    "        # Compute PSNR\n",
    "        psnr_values[i] = psnr(hr, sr)\n",
    "        \n",
    "        # Compute SSIM\n",
    "        ssim_values[i] = ssim(hr, sr, multichannel=True, channel_axis=0, data_range=sr.max() - sr.min())\n",
    "    \n",
    "    return psnr_values, ssim_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T22:03:02.730828Z",
     "start_time": "2024-04-20T22:03:02.721825Z"
    }
   },
   "outputs": [],
   "source": [
    "from email_notifier import EmailNotifier\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv(\".keys\")\n",
    "\n",
    "email_credentials = {'smtp_server':os.environ['email-smtp-server'],\n",
    "                    'smtp_port':os.environ['email-smtp-port'],\n",
    "                    'sender_email':os.environ['email-id'],\n",
    "                    'sender_password':os.environ['email-pw']}\n",
    "\n",
    "em = EmailNotifier(**email_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T22:03:02.734130Z",
     "start_time": "2024-04-20T22:03:02.732015Z"
    }
   },
   "outputs": [],
   "source": [
    "subject=\"Notification for SRGAN Training in College\"\n",
    "recipients=\"aadilzikre@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-20T22:03:01.191Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-04-06T16:07:23.489111Z",
     "iopub.status.busy": "2024-04-06T16:07:23.488500Z",
     "iopub.status.idle": "2024-04-06T22:56:42.764079Z",
     "shell.execute_reply": "2024-04-06T22:56:42.762615Z",
     "shell.execute_reply.started": "2024-04-06T16:07:23.489079Z"
    },
    "executionInfo": {
     "elapsed": 5260841,
     "status": "ok",
     "timestamp": 1712543327631,
     "user": {
      "displayName": "Aadil Iliyas Zikre",
      "userId": "11139065713760395341"
     },
     "user_tz": 240
    },
    "id": "XIjWgvC8teTm",
    "outputId": "7851615c-e863-4e7c-90cc-6d01b197e6b5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# generator parameters: 1549478\n",
      "# discriminator parameters: 5215425\n",
      "netG sent to cuda\n",
      "netD sent to cuda\n",
      "generator criterion sent to cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2001/4000] Loss_D: 0.000003 Loss_G: 0.0042 D(x): 0.999999 D(G(z)): 0.000002: 100%|███████████████████████████████████| 77/77 [00:49<00:00,  1.55it/s]\n",
      "[converting LR images to SR images] PSNR: 21.8725 dB SSIM: 0.6767: 100%|███████████████████████████████████████████| 100/100 [00:00<00:00, 112.88it/s]\n",
      "[2002/4000] Loss_D: 0.000001 Loss_G: 0.0042 D(x): 0.999999 D(G(z)): 0.000000: 100%|███████████████████████████████████| 77/77 [00:49<00:00,  1.54it/s]\n",
      "[converting LR images to SR images] PSNR: 21.9022 dB SSIM: 0.6773: 100%|███████████████████████████████████████████| 100/100 [00:00<00:00, 118.23it/s]\n",
      "[2003/4000] Loss_D: 0.000002 Loss_G: 0.0041 D(x): 0.999998 D(G(z)): 0.000001:  40%|██████████████                     | 31/77 [00:20<00:30,  1.53it/s]"
     ]
    }
   ],
   "source": [
    "## train.py\n",
    "# aliased imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as utils\n",
    "\n",
    "# package imports no alias\n",
    "import torch\n",
    "import os\n",
    "# import pytorch_ssim\n",
    "import math\n",
    "\n",
    "# Class/Fuction Imports\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Local Imports\n",
    "# from generator import ganGenerator\n",
    "# from discriminator import ganDiscriminator\n",
    "# from generator_loss import GeneratorLoss\n",
    "# from data_utils import Div2kValDataset, Div2kTrainDataset, display_transform\n",
    "\n",
    "# filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "train_hr_loc = \"data/train_1\"\n",
    "valid_hr_loc = \"data/validation_1\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    NUM_EPOCHS = 4000\n",
    "    START_AT = 2001\n",
    "    LOAD_AT = START_AT - 1\n",
    "    \n",
    "\n",
    "    train_set = Div2kTrainDataset(train_hr_loc)\n",
    "    val_set = Div2kValDataset(valid_hr_loc)\n",
    "    train_loader = DataLoader(dataset=train_set, batch_size=64, shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_set, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "    netG = ganGenerator()\n",
    "    if LOAD_AT >= 0:\n",
    "        netG.load_state_dict(torch.load(f\"epochs/netG_epoch_4_{LOAD_AT}.pth\"), strict=False)\n",
    "    print('# generator parameters:', sum(param.numel() for param in netG.parameters()))\n",
    "    netD = ganDiscriminator()\n",
    "    if LOAD_AT >= 0:\n",
    "        netD.load_state_dict(torch.load(f\"epochs/netD_epoch_4_{LOAD_AT}.pth\"), strict=False)\n",
    "    print('# discriminator parameters:', sum(param.numel() for param in netD.parameters()))\n",
    "\n",
    "    generator_criterion = GeneratorLoss()\n",
    "\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device_gen = torch.device(\"cuda:1\")\n",
    "    device_disc = torch.device(\"cuda:1\")\n",
    "    # if torch.cuda.is_available():\n",
    "    #     netG.to(device)\n",
    "    #     print(\"netG sent to cuda\")\n",
    "    #     netD.to(device)\n",
    "    #     print(\"netD sent to cuda\")\n",
    "    #     generator_criterion.to(device)\n",
    "    #     print(\"generator criterion sent to cuda\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        netG.to(device_gen)\n",
    "        print(\"netG sent to cuda\")\n",
    "        netD.to(device_disc)\n",
    "        print(\"netD sent to cuda\")\n",
    "        generator_criterion.to(device_gen)\n",
    "        print(\"generator criterion sent to cuda\")\n",
    "\n",
    "    optimizerG = optim.Adam(netG.parameters(), lr=1e-5)\n",
    "    optimizerD = optim.Adam(netD.parameters(), lr=1e-5)\n",
    "\n",
    "    results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n",
    "\n",
    "    for epoch in range(START_AT, NUM_EPOCHS + 1):\n",
    "        train_bar = tqdm(train_loader, ncols=150)\n",
    "        running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
    "\n",
    "        netG.train()\n",
    "        netD.train()\n",
    "\n",
    "        for target, source in train_bar:\n",
    "            g_update_first = True\n",
    "            batch_size = target.size(0)\n",
    "            running_results['batch_sizes'] += batch_size\n",
    "\n",
    "            ############################\n",
    "            # (1) Update D network: maximize D(x)-1-D(G(z))\n",
    "            ###########################\n",
    "            real_img = Variable(target)\n",
    "            if torch.cuda.is_available():\n",
    "                real_img = real_img.to(device_disc)\n",
    "            z = Variable(source)\n",
    "            if torch.cuda.is_available():\n",
    "                z = z.to(device_gen)\n",
    "            fake_img = netG(z).to(device_disc)\n",
    "\n",
    "            netD.zero_grad()\n",
    "            real_out = netD(real_img).mean()\n",
    "            fake_out = netD(fake_img).mean()\n",
    "            d_loss = 1 - real_out + fake_out\n",
    "            d_loss.backward()\n",
    "            optimizerD.step()\n",
    "\n",
    "            ############################\n",
    "            # (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n",
    "            ###########################\n",
    "            netG.zero_grad()\n",
    "            ## The two lines below are added to prevent runetime error in Google Colab ##\n",
    "#             fake_img = netG(z).detach().to(device_disc)\n",
    "            fake_img = netG(z).to(device_disc)\n",
    "            fake_out = netD(fake_img).mean().to(device_gen)\n",
    "            real_img = real_img.to(device_gen)\n",
    "            fake_img = fake_img.to(device_gen)\n",
    "            ##\n",
    "            g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
    "            g_loss.backward()\n",
    "\n",
    "#             fake_img = netG(z).detach().to(device_disc)\n",
    "            fake_img = netG(z).to(device_disc)\n",
    "            fake_out = netD(fake_img).mean()\n",
    "\n",
    "            optimizerG.step()\n",
    "\n",
    "            # loss for current batch before optimization\n",
    "            running_results['g_loss'] += g_loss.item() * batch_size\n",
    "            running_results['d_loss'] += d_loss.item() * batch_size\n",
    "            running_results['d_score'] += real_out.item() * batch_size\n",
    "            running_results['g_score'] += fake_out.item() * batch_size\n",
    "\n",
    "            train_bar.set_description(desc='[%d/%d] Loss_D: %.6f Loss_G: %.4f D(x): %.6f D(G(z)): %.6f' % (\n",
    "                epoch, NUM_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n",
    "                running_results['g_loss'] / running_results['batch_sizes'],\n",
    "                running_results['d_score'] / running_results['batch_sizes'],\n",
    "                running_results['g_score'] / running_results['batch_sizes']))\n",
    "\n",
    "        netG.eval()\n",
    "        out_path = 'training_results/'\n",
    "        if not os.path.exists(out_path):\n",
    "            os.makedirs(out_path)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(val_loader, ncols=150)\n",
    "            validation_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n",
    "            val_images = []\n",
    "            for val_hr, val_lr in val_bar:\n",
    "                batch_size = val_lr.size(0)\n",
    "                validation_results['batch_sizes'] += batch_size\n",
    "                lr = val_lr\n",
    "                hr = val_hr\n",
    "                if torch.cuda.is_available():\n",
    "                    lr = lr.to(device_gen)\n",
    "                    hr = hr.to(device_gen)\n",
    "                sr = netG(lr)\n",
    "\n",
    "                batch_mse = ((sr - hr) ** 2).data.mean()\n",
    "                validation_results['mse'] += batch_mse * batch_size\n",
    "                # batch_ssim = pytorch_ssim.ssim(sr, hr).item()\n",
    "                _, ssim_sr = compute_metrics_batch(hr.cpu().numpy(), sr.cpu().numpy())\n",
    "                batch_ssim = ssim_sr / batch_size\n",
    "                validation_results['ssims'] += batch_ssim * batch_size\n",
    "                validation_results['psnr'] = 10 * math.log10((hr.max()**2) / (validation_results['mse'] / validation_results['batch_sizes']))\n",
    "                validation_results['ssim'] = validation_results['ssims'] / validation_results['batch_sizes']\n",
    "                val_bar.set_description(\n",
    "                    desc='[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f' % (\n",
    "                        validation_results['psnr'], validation_results['ssim']))\n",
    "\n",
    "                val_images.extend(\n",
    "                    [display_transform()(lr.squeeze(0)), display_transform()(hr.data.cpu().squeeze(0)),\n",
    "                        display_transform()(sr.data.cpu().squeeze(0))])\n",
    "            if epoch%100==0:\n",
    "                val_images = torch.stack(val_images)\n",
    "                val_images = torch.chunk(val_images, val_images.size(0) // 15)\n",
    "                val_save_bar = tqdm(val_images, desc='[saving training results]')\n",
    "                index = 1\n",
    "                for image in val_save_bar:\n",
    "                    image = utils.make_grid(image, nrow=3, padding=5)\n",
    "                    utils.save_image(image, out_path + 'epoch_%d_index_%d.png' % (epoch, index), padding=5)\n",
    "                    index += 1\n",
    "\n",
    "        if not os.path.exists('epochs/'):\n",
    "            os.makedirs('epochs/')\n",
    "        # save model parameters\n",
    "        if epoch%100==0:\n",
    "            torch.save(netG.state_dict(), 'epochs/netG_epoch_%d_%d.pth' % (4, epoch))\n",
    "            torch.save(netD.state_dict(), 'epochs/netD_epoch_%d_%d.pth' % (4, epoch))\n",
    "            \n",
    "        if epoch%100==0:\n",
    "            training_res_string = '[%d/%d] Loss_D: %.6f Loss_G: %.4f D(x): %.6f D(G(z)): %.6f' % (\n",
    "                epoch, NUM_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n",
    "                running_results['g_loss'] / running_results['batch_sizes'],\n",
    "                running_results['d_score'] / running_results['batch_sizes'],\n",
    "                running_results['g_score'] / running_results['batch_sizes'])\n",
    "            body = f\"\"\"\n",
    "Epochs {epoch}/{NUM_EPOCHS} complete. \n",
    "\n",
    "Training Result String = {training_res_string}\n",
    "\n",
    "Validation Results = {validation_results}\n",
    "            \"\"\"\n",
    "            em.send_email(subject, body, recipients, attachments=[out_path + 'epoch_%d_index_%d.png' % (epoch, 20)])\n",
    "            \n",
    "        # save loss\\scores\\psnr\\ssim\n",
    "        results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n",
    "        results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n",
    "        results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n",
    "        results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])\n",
    "        results['psnr'].append(validation_results['psnr'])\n",
    "        results['ssim'].append(validation_results['ssim'])\n",
    "\n",
    "#         if epoch % 10 == 0 and epoch != 0:\n",
    "#             out_path = '/kaggle/working/statistics/'\n",
    "#             if not os.path.exists(out_path):\n",
    "#                 os.makedirs(out_path)\n",
    "#             data_frame = pd.DataFrame(\n",
    "#                 data={'Loss_D': results['d_loss'], 'Loss_G': results['g_loss'], 'Score_D': results['d_score'],\n",
    "#                         'Score_G': results['g_score'], 'PSNR': results['psnr'], 'SSIM': 0},\n",
    "#                 index=range(1, epoch + 1))\n",
    "#             data_frame.to_csv(out_path + 'srf_' + str(4) + '_train_results.csv', index_label='Epoch')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP39wtWOZqy868bC0BOWbSK",
   "gpuType": "T4",
   "mount_file_id": "1K-QYD5WvmMIPHLz1D0tJW6DuIWeVRP1M",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "season4",
   "language": "python",
   "name": "season4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
