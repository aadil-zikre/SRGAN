{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Css1mfWZyt0H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR3rNcmwy52Y"
      },
      "outputs": [],
      "source": [
        "class ganGenerator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ganGenerator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, stride=1)\n",
        "        self.prelu1 = nn.PReLU()\n",
        "        self.GRB1 = GeneratorResidualBlock()\n",
        "        self.GRB2 = GeneratorResidualBlock()\n",
        "        self.GRB3 = GeneratorResidualBlock()\n",
        "        self.GRB4 = GeneratorResidualBlock()\n",
        "        self.GRB5 = GeneratorResidualBlock()\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, stride=1)\n",
        "        self.pxlshuffle1 = nn.PixelShuffle(2)\n",
        "        self.prelu2 = nn.PReLU()\n",
        "        self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1)\n",
        "        self.pxlshuffle2 = nn.PixelShuffle(2)\n",
        "        self.prelu3 = nn.PReLU()\n",
        "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=3, kernel_size=9, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv1(x)\n",
        "        x1 = self.prelu1(x1)\n",
        "\n",
        "        x2 = self.GRB1(x1)\n",
        "        x2 = self.GRB2(x2)\n",
        "        x2 = self.GRB3(x2)\n",
        "        x2 = self.GRB4(x2)\n",
        "        x2 = self.GRB5(x2)\n",
        "\n",
        "        x2 = self.conv2(x2)\n",
        "        x2 = F.bn1(x2)\n",
        "        x3 = x1 + x2\n",
        "\n",
        "        x3 = self.conv3(x3)\n",
        "        x3 = self.pxlshuffle1(x3)\n",
        "        x3 = self.prelu2(x3)\n",
        "        x3 = self.conv4(x3)\n",
        "        x3 = self.pxlshuffle2(x3)\n",
        "        x4 = self.prelu3(x3)\n",
        "\n",
        "        x5 = self.conv5(x4)\n",
        "\n",
        "        return x5\n",
        "\n",
        "class GeneratorResidualBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GeneratorResidualBlock, self).__init__()\n",
        "        # convolution\n",
        "        self.conv1 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "        # batchnorm\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        # prelu\n",
        "        self.prelu1 = nn.PReLU()\n",
        "        #convolution\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "        # batchnorm\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        # prelu\n",
        "        self.prelu2 = nn.PReLU()\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.prelu1(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.prelu2(out)\n",
        "        return out + x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G93fi0j2y5jr"
      },
      "outputs": [],
      "source": [
        "class ganDiscriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ganDiscriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1,)\n",
        "        self.lrelu1 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.lrelu2 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.lrelu3 = nn.LeakyReLU()\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=2)\n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        self.lrelu4 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1)\n",
        "        self.bn5 = nn.BatchNorm2d(256)\n",
        "        self.lrelu5 = nn.LeakyReLU()\n",
        "        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=2)\n",
        "        self.bn6 = nn.BatchNorm2d(256)\n",
        "        self.lrelu6 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1)\n",
        "        self.bn7 = nn.BatchNorm2d(512)\n",
        "        self.lrelu7 = nn.LeakyReLU()\n",
        "        self.conv8 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=2)\n",
        "        self.bn8 = nn.BatchNorm2d(512)\n",
        "        self.lrelu8 = nn.LeakyReLU()\n",
        "\n",
        "        self.flat = nn.Flatten()\n",
        "\n",
        "        self.dense9 = nn.Linear(out_features=1024, bias=True)\n",
        "        self.lrelu9 = nn.LeakyReLU()\n",
        "\n",
        "        self.dense10 = nn.Linear(out_features=1, bias=True)\n",
        "        self.sigmoid10 = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv1(x)\n",
        "        x1 = self.lrelu1(x1)\n",
        "\n",
        "        x2 = self.conv2(x1)\n",
        "        x2 = self.bn2(x2)\n",
        "        x2 = self.lrelu2(x2)\n",
        "\n",
        "        x3 = self.conv3(x2)\n",
        "        x3 = self.bn3(x3)\n",
        "        x3 = self.lrelu3(x3)\n",
        "\n",
        "        x4 = self.conv4(x3)\n",
        "        x4 = self.bn4(x4)\n",
        "        x4 = self.lrelu4(x4)\n",
        "\n",
        "        x5 = self.conv5(x4)\n",
        "        x5 = self.bn5(x5)\n",
        "        x5 = self.lrelu5(x5)\n",
        "\n",
        "        x6 = self.conv6(x5)\n",
        "        x6 = self.bn6(x6)\n",
        "        x6 = self.lrelu6(x6)\n",
        "\n",
        "        x7 = self.conv7(x6)\n",
        "        x7 = self.bn7(x7)\n",
        "        x7 = self.lrelu7(x7)\n",
        "\n",
        "        x8 = self.conv8(x7)\n",
        "        x8 = self.bn8(x8)\n",
        "        x8 = self.lrelu8(x8)\n",
        "\n",
        "        x9 = self.flat(x8)\n",
        "\n",
        "        x10 = self.dense9(x9)\n",
        "        x10 = self.lrelu9(x10)\n",
        "\n",
        "        x11 = self.dense10(x10)\n",
        "        x11 = self.sigmoid10(x11)\n",
        "\n",
        "        return x11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-YLLKyRy5eN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision.models.vgg import vgg16\n",
        "\n",
        "class TVLoss(nn.Module):\n",
        "    def __init__(self, tv_loss_weight=1):\n",
        "        super(TVLoss, self).__init__()\n",
        "        self.tv_loss_weight = tv_loss_weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, h_x, w_x = x.size()\n",
        "        count_h = self.tensor_size(x[:, :, 1:, :])\n",
        "        count_w = self.tensor_size(x[:, :, :, 1:])\n",
        "        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()\n",
        "        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()\n",
        "        return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
        "\n",
        "    @staticmethod\n",
        "    def tensor_size(t):\n",
        "        return t.size()[1:4]\n",
        "\n",
        "class GeneratorLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GeneratorLoss, self).__init__()\n",
        "        vgg = vgg16(pretrained=True)\n",
        "        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
        "        for param in loss_network.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.loss_network = loss_network\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.tv_loss = TVLoss()\n",
        "\n",
        "    def forward(self, out_labels, out_images, target_images):\n",
        "        # Adversarial Loss\n",
        "        adversarial_loss = torch.mean(1 - out_labels)\n",
        "        # Perception Loss\n",
        "        perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
        "        # Image Loss\n",
        "        image_loss = self.mse_loss(out_images, target_images)\n",
        "        # TV Loss\n",
        "        tv_loss = self.tv_loss(out_images)\n",
        "        return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVrtUOmOy5bm"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, ToTensor, ToPILImage, CenterCrop, transforms, Resize\n",
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n",
        "\n",
        "hr_target_size = (1020, 2040)\n",
        "\n",
        "hr_transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.rotate(0) if img.size[0] > img.size[1] else img.rotate(90)),\n",
        "    transforms.CenterCrop(hr_target_size),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "lr_target_size = (1020 // 4, 2040 // 4)\n",
        "\n",
        "lr_transform = transforms.Compose([\n",
        "    transforms.Lambda(lambda img: img.rotate(0) if img.size[0] > img.size[1] else img.rotate(90)),\n",
        "    transforms.CenterCrop(lr_target_size),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "class Div2kTrainDataset(Dataset):\n",
        "    def __init__(self, hr_base_dir, lr_base_dir):\n",
        "        super(Div2kTrainDataset, self).__init__()\n",
        "\n",
        "        self.hr_base_dir = hr_base_dir\n",
        "        self.lr_base_dir = lr_base_dir\n",
        "\n",
        "        self.hr_image_filenames = [f'{self.hr_base_dir}/{i:0>4}.png' for i in range(1, 801)]\n",
        "        self.lr_image_filenames = [f'{self.lr_base_dir}/{i:0>4}x4d.png' for i in range(1, 801)]\n",
        "\n",
        "        self.hr_transform = hr_transform\n",
        "        self.lr_transform = lr_transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        hr_image = self.hr_transform(Image.open(self.hr_image_filenames[index]))\n",
        "        lr_image = self.lr_transform(Image.open(self.lr_image_filenames[index]))\n",
        "        return hr_image, lr_image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hr_image_filenames)\n",
        "\n",
        "class Div2kValDataset(Dataset):\n",
        "    def __init__(self, hr_base_dir, lr_base_dir):\n",
        "        super(Div2kValDataset, self).__init__()\n",
        "\n",
        "        self.hr_base_dir = hr_base_dir\n",
        "        self.lr_base_dir = lr_base_dir\n",
        "\n",
        "        self.hr_image_filenames = [f'{self.hr_base_dir}/{i:0>4}.png' for i in range(801, 901)]\n",
        "        self.lr_image_filenames = [f'{self.lr_base_dir}/{i:0>4}x4d.png' for i in range(801, 901)]\n",
        "\n",
        "        self.hr_transform = hr_transform\n",
        "        self.lr_transform = lr_transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        hr_image = self.hr_transform(Image.open(self.hr_image_filenames[index]))\n",
        "        lr_image = self.lr_transform(Image.open(self.lr_image_filenames[index]))\n",
        "        return hr_image, lr_image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.hr_image_filenames)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBkrCFw7Tldy"
      },
      "outputs": [],
      "source": [
        "def display_transform():\n",
        "    return Compose([\n",
        "        ToPILImage(),\n",
        "        Resize(400),\n",
        "        CenterCrop(400),\n",
        "        ToTensor()\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEgrGXWXNC9b"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMy3oOpsy5ZR"
      },
      "outputs": [],
      "source": [
        "train_set = Div2kTrainDataset('data/DIV2K_train_HR', 'data/DIV2K_train_LR_difficult')\n",
        "val_set = Div2kValDataset('data/DIV2K_valid_HR', 'data/DIV2K_valid_LR_difficult' )\n",
        "train_loader = DataLoader(dataset=train_set, num_workers=1, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_set, num_workers=1, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "medJDWGhO6ms"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5gk0I_YPMSL"
      },
      "outputs": [],
      "source": [
        "NUM_EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi-3ZZSnRRJn"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tz5zd0ybS8WD"
      },
      "outputs": [],
      "source": [
        "import pytorch_ssim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5WuaGTzTHtv"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zC6AhTOUFx5"
      },
      "outputs": [],
      "source": [
        "import torchvision.utils as utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzAtnYtiy5TL"
      },
      "outputs": [],
      "source": [
        "netG = ganGenerator()\n",
        "print('# generator parameters:', sum(param.numel() for param in netG.parameters()))\n",
        "netD = ganDiscriminator()\n",
        "print('# discriminator parameters:', sum(param.numel() for param in netD.parameters()))\n",
        "\n",
        "generator_criterion = GeneratorLoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    netG.cuda()\n",
        "    netD.cuda()\n",
        "    generator_criterion.cuda()\n",
        "\n",
        "optimizerG = optim.Adam(netG.parameters())\n",
        "optimizerD = optim.Adam(netD.parameters())\n",
        "\n",
        "results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train_bar = tqdm(train_loader)\n",
        "    running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
        "\n",
        "    netG.train()\n",
        "    netD.train()\n",
        "\n",
        "    for target, source in train_bar:\n",
        "        g_update_first = True\n",
        "        batch_size = target.size(0)\n",
        "        running_results['batch_sizes'] += batch_size\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize D(x)-1-D(G(z))\n",
        "        ###########################\n",
        "        real_img = Variable(target)\n",
        "        if torch.cuda.is_available():\n",
        "            real_img = real_img.cuda()\n",
        "        z = Variable(source)\n",
        "        if torch.cuda.is_available():\n",
        "            z = z.cuda()\n",
        "        fake_img = netG(z)\n",
        "\n",
        "        netD.zero_grad()\n",
        "        real_out = netD(real_img).mean()\n",
        "        fake_out = netD(fake_img).mean()\n",
        "        d_loss = 1 - real_out + fake_out\n",
        "        d_loss.backward(retain_graph=True)\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        ## The two lines below are added to prevent runetime error in Google Colab ##\n",
        "        fake_img = netG(z)\n",
        "        fake_out = netD(fake_img).mean()\n",
        "        ##\n",
        "        g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
        "        g_loss.backward()\n",
        "\n",
        "        # fake_img = netG(z)\n",
        "        # fake_out = netD(fake_img).mean()\n",
        "\n",
        "        optimizerG.step()\n",
        "\n",
        "        # loss for current batch before optimization\n",
        "        running_results['g_loss'] += g_loss.item() * batch_size\n",
        "        running_results['d_loss'] += d_loss.item() * batch_size\n",
        "        running_results['d_score'] += real_out.item() * batch_size\n",
        "        running_results['g_score'] += fake_out.item() * batch_size\n",
        "\n",
        "        train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' % (\n",
        "            epoch, NUM_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n",
        "            running_results['g_loss'] / running_results['batch_sizes'],\n",
        "            running_results['d_score'] / running_results['batch_sizes'],\n",
        "            running_results['g_score'] / running_results['batch_sizes']))\n",
        "\n",
        "    netG.eval()\n",
        "    out_path = 'training_results/'\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        val_bar = tqdm(val_loader)\n",
        "        validation_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n",
        "        val_images = []\n",
        "        for val_hr, val_lr in val_bar:\n",
        "            batch_size = val_lr.size(0)\n",
        "            validation_results['batch_sizes'] += batch_size\n",
        "            lr = val_lr\n",
        "            hr = val_hr\n",
        "            if torch.cuda.is_available():\n",
        "                lr = lr.cuda()\n",
        "                hr = hr.cuda()\n",
        "            sr = netG(lr)\n",
        "\n",
        "            batch_mse = ((sr - hr) ** 2).data.mean()\n",
        "            validation_results['mse'] += batch_mse * batch_size\n",
        "            batch_ssim = pytorch_ssim.ssim(sr, hr).item()\n",
        "            validation_results['ssims'] += batch_ssim * batch_size\n",
        "            validation_results['psnr'] = 10 * math.log10((hr.max()**2) / (validation_results['mse'] / validation_results['batch_sizes']))\n",
        "            validation_results['ssim'] = validation_results['ssims'] / validation_results['batch_sizes']\n",
        "            val_bar.set_description(\n",
        "                desc='[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f' % (\n",
        "                    validation_results['psnr'], validation_results['ssim']))\n",
        "\n",
        "            val_images.extend(\n",
        "                [display_transform()(lr.squeeze(0)), display_transform()(hr.data.cpu().squeeze(0)),\n",
        "                    display_transform()(sr.data.cpu().squeeze(0))])\n",
        "        val_images = torch.stack(val_images)\n",
        "        val_images = torch.chunk(val_images, val_images.size(0) // 15)\n",
        "        val_save_bar = tqdm(val_images, desc='[saving training results]')\n",
        "        index = 1\n",
        "        for image in val_save_bar:\n",
        "            image = utils.make_grid(image, nrow=3, padding=5)\n",
        "            utils.save_image(image, out_path + 'epoch_%d_index_%d.png' % (epoch, index), padding=5)\n",
        "            index += 1\n",
        "\n",
        "    # save model parameters\n",
        "    torch.save(netG.state_dict(), 'epochs/netG_epoch_%d_%d.pth' % (4, epoch))\n",
        "    torch.save(netD.state_dict(), 'epochs/netD_epoch_%d_%d.pth' % (4, epoch))\n",
        "    # save loss\\scores\\psnr\\ssim\n",
        "    results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n",
        "    results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n",
        "    results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n",
        "    results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])\n",
        "    results['psnr'].append(validation_results['psnr'])\n",
        "    results['ssim'].append(validation_results['ssim'])\n",
        "\n",
        "    if epoch % 10 == 0 and epoch != 0:\n",
        "        out_path = 'statistics/'\n",
        "        data_frame = pd.DataFrame(\n",
        "            data={'Loss_D': results['d_loss'], 'Loss_G': results['g_loss'], 'Score_D': results['d_score'],\n",
        "                    'Score_G': results['g_score'], 'PSNR': results['psnr'], 'SSIM': results['ssim']},\n",
        "            index=range(1, epoch + 1))\n",
        "        data_frame.to_csv(out_path + 'srf_' + str(4) + '_train_results.csv', index_label='Epoch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUFss1wwy5L9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JnhrI6oy5JH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkB77x8sy5Gg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2BIajoFy5BA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN6Irfpuy4pv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
